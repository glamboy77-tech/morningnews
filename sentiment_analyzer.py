from google import genai
import json
import os
from datetime import datetime, timedelta
from config import config

class SentimentAnalyzer:
    def __init__(self):
        self.client = genai.Client(api_key=config.gemini_api_key)
        self.cache_dir = "sentiment_cache"
        os.makedirs(self.cache_dir, exist_ok=True)
        
    def is_trading_day(self):
        """
        í˜„ì¬ê°€ í‰ì¼ ì¥ ì¤‘ì¸ì§€, ì•„ë‹ˆë©´ ì£¼ë§/ê³µíœ´ì¼ì¸ì§€ íŒë‹¨
        Returns: 'trading' (í‰ì¼ ì¥ ì¤‘) or 'accumulation' (ì£¼ë§/ê³µíœ´ì¼)
        """
        now = datetime.now()
        
        # ì£¼ë§ ì²´í¬
        if now.weekday() >= 5:  # í† ìš”ì¼(5), ì¼ìš”ì¼(6)
            return 'accumulation'
        
        # ê³µíœ´ì¼ ì²´í¬ (ê°„ë‹¨í•œ í•œêµ­ ê³µíœ´ì¼ ëª©ë¡)
        month = now.month
        day = now.day
        
        korean_holidays = {
            (1, 1): "ì‹ ì •",
            (3, 1): "ì‚¼ì¼ì ˆ",
            (5, 5): "ì–´ë¦°ì´ë‚ ",
            (6, 6): "í˜„ì¶©ì¼",
            (8, 15): "ê´‘ë³µì ˆ",
            (10, 3): "ê°œì²œì ˆ",
            (10, 9): "í•œê¸€ë‚ ",
            (12, 25): "ì„±íƒ„ì ˆ"
        }
        
        if (month, day) in korean_holidays:
            return 'accumulation'
        
        # ì¥ ì‹œê°„ ì²´í¬ (í‰ì¼ 9:00-15:30)
        if 9 <= now.hour < 16:
            return 'trading'
        else:
            return 'accumulation'
    
    def is_first_trading_day_after_holiday(self):
        """
        ì›”ìš”ì¼ ë˜ëŠ” ê³µíœ´ì¼ ë‹¤ìŒ ë‚ ì¸ì§€ íŒë‹¨
        Returns: True if today is the first trading day after a holiday/weekend
        """
        now = datetime.now()
        
        # ì›”ìš”ì¼ ì²´í¬
        if now.weekday() == 0:  # 0ì€ ì›”ìš”ì¼
            return True
        
        # ì–´ì œê°€ ê³µíœ´ì¼ì´ì—ˆëŠ”ì§€ ì²´í¬
        yesterday = now - timedelta(days=1)
        yesterday_month = yesterday.month
        yesterday_day = yesterday.day
        
        korean_holidays = {
            (1, 1): "ì‹ ì •",
            (3, 1): "ì‚¼ì¼ì ˆ",
            (5, 5): "ì–´ë¦°ì´ë‚ ",
            (6, 6): "í˜„ì¶©ì¼",
            (8, 15): "ê´‘ë³µì ˆ",
            (10, 3): "ê°œì²œì ˆ",
            (10, 9): "í•œê¸€ë‚ ",
            (12, 25): "ì„±íƒ„ì ˆ"
        }
        
        # ì–´ì œê°€ ì£¼ë§ì´ê±°ë‚˜ ê³µíœ´ì¼ì´ì—ˆìœ¼ë©´ True
        if yesterday.weekday() >= 5 or (yesterday_month, yesterday_day) in korean_holidays:
            return True
        
        return False
    
    def get_time_weight(self, news_datetime):
        """
        ë‰´ìŠ¤ ì‹œê°„ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ê³„ì‚°
        - ì–´ì œ 15:30 ~ ì˜¤ëŠ˜ 08:30: ê°€ì¤‘ì¹˜ 2.0 (ì¥ì™¸ ë‰´ìŠ¤)
        - ì–´ì œ 09:00 ~ 15:30: ê°€ì¤‘ì¹˜ 1.0 (ì¥ì¤‘ ë‰´ìŠ¤)
        - ê·¸ ì™¸: ê°€ì¤‘ì¹˜ 0.5 (ê¸°íƒ€)
        """
        now = datetime.now()
        yesterday = now - timedelta(days=1)
        
        # ì¥ì™¸ ì‹œê°„ëŒ€: ì–´ì œ 15:30 ~ ì˜¤ëŠ˜ 08:30
        market_close_yesterday = yesterday.replace(hour=15, minute=30, second=0, microsecond=0)
        market_open_today = now.replace(hour=8, minute=30, second=0, microsecond=0)
        
        # ì¥ì¤‘ ì‹œê°„ëŒ€: ì–´ì œ 09:00 ~ 15:30
        market_open_yesterday = yesterday.replace(hour=9, minute=0, second=0, microsecond=0)
        
        if market_close_yesterday <= news_datetime <= market_open_today:
            return 2.0  # ì¥ì™¸ ë‰´ìŠ¤ (ê°€ì¥ ì¤‘ìš”)
        elif market_open_yesterday <= news_datetime < market_close_yesterday:
            return 1.0  # ì¥ì¤‘ ë‰´ìŠ¤ (ì´ë¯¸ ë°˜ì˜ë¨)
        else:
            return 0.5  # ê¸°íƒ€ ë‰´ìŠ¤
    
    def filter_trading_signals(self, categorized_news):
        """
        ë§¤ë§¤ë´‡ìš© í˜¸ì¬/ì•…ì¬ í•„í„°ë§
        - ì¥ì™¸ ë‰´ìŠ¤(ì–´ì œ 15:30~ì˜¤ëŠ˜ 08:30)ì— ê°€ì¤‘ì¹˜ ë¶€ì—¬
        """
        filtered_news = {}
        
        for category, items in categorized_news.items():
            filtered_items = []
            
            for item in items:
                news_time = item.get('published_dt')
                if news_time:
                    weight = self.get_time_weight(news_time)
                    # ê°€ì¤‘ì¹˜ê°€ 1.0 ì´ìƒì¸ ë‰´ìŠ¤ë§Œ í¬í•¨ (ì¥ì™¸ + ì¥ì¤‘)
                    if weight >= 1.0:
                        item['time_weight'] = weight
                        filtered_items.append(item)
            
            if filtered_items:
                filtered_news[category] = filtered_items
        
        return filtered_news
    
    def get_cache_filename(self, date_str=None):
        """
        ìºì‹œ íŒŒì¼ëª… ìƒì„±
        """
        if date_str is None:
            date_str = datetime.now().strftime("%Y%m%d")
        return os.path.join(self.cache_dir, f"sentiment_{date_str}.json")
    
    def load_cached_data(self, date_str=None):
        """
        ìºì‹œëœ ë°ì´í„° ë¡œë“œ
        """
        cache_file = self.get_cache_filename(date_str)
        if os.path.exists(cache_file):
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None
    
    def save_cached_data(self, data, date_str=None):
        """
        ë°ì´í„° ìºì‹œ ì €ì¥
        """
        cache_file = self.get_cache_filename(date_str)
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"âœ… ê°ì„± ë°ì´í„° ìºì‹œ ì €ì¥: {cache_file}")
        except Exception as e:
            print(f"ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def merge_sentiment_data(self, current_data, cached_data):
        """
        í˜„ì¬ ë°ì´í„°ì™€ ìºì‹œëœ ë°ì´í„°ë¥¼ ë³‘í•©
        - ë™ì¼ ì¢…ëª©ì€ ì ìˆ˜ í•©ì‚°
        - ìƒˆë¡œìš´ ì¢…ëª©ì€ ì¶”ê°€
        """
        if not cached_data:
            return current_data
        
        merged = {
            "section_summaries": cached_data.get("section_summaries", {}),
            "hojae": [],
            "akjae": [],
            "merged_dates": cached_data.get("merged_dates", [])
        }
        
        # í˜„ì¬ ë‚ ì§œ ì¶”ê°€
        today = datetime.now().strftime("%Y-%m-%d")
        if today not in merged["merged_dates"]:
            merged["merged_dates"].append(today)
        
        # í˜¸ì¬ ë°ì´í„° ë³‘í•©
        hojae_dict = {}
        
        # ìºì‹œëœ í˜¸ì¬ ë°ì´í„° ì²˜ë¦¬
        for item in cached_data.get("hojae", []):
            if ":" in item:
                company, reason = item.split(":", 1)
                hojae_dict[company.strip()] = {
                    "reason": reason.strip(),
                    "count": 1,
                    "score": 1
                }
        
        # í˜„ì¬ í˜¸ì¬ ë°ì´í„° ì²˜ë¦¬ ë° ë³‘í•©
        for item in current_data.get("hojae", []):
            if ":" in item:
                company, reason = item.split(":", 1)
                company = company.strip()
                if company in hojae_dict:
                    hojae_dict[company]["count"] += 1
                    hojae_dict[company]["score"] += 1
                    # ìµœì‹  ì´ìœ ë¡œ ì—…ë°ì´íŠ¸
                    hojae_dict[company]["reason"] = reason.strip()
                else:
                    hojae_dict[company] = {
                        "reason": reason.strip(),
                        "count": 1,
                        "score": 1
                    }
        
        # ë³‘í•©ëœ í˜¸ì¬ ë°ì´í„° ìƒì„±
        for company, data in hojae_dict.items():
            merged["hojae"].append(f"{company}: {data['reason']} ({data['count']}íšŒ)")
        
        # ì•…ì¬ ë°ì´í„° ë³‘í•© (ë™ì¼ ë¡œì§)
        akjae_dict = {}
        
        for item in cached_data.get("akjae", []):
            if ":" in item:
                company, reason = item.split(":", 1)
                akjae_dict[company.strip()] = {
                    "reason": reason.strip(),
                    "count": 1,
                    "score": -1
                }
        
        for item in current_data.get("akjae", []):
            if ":" in item:
                company, reason = item.split(":", 1)
                company = company.strip()
                if company in akjae_dict:
                    akjae_dict[company]["count"] += 1
                    akjae_dict[company]["score"] -= 1
                    akjae_dict[company]["reason"] = reason.strip()
                else:
                    akjae_dict[company] = {
                        "reason": reason.strip(),
                        "count": 1,
                        "score": -1
                    }
        
        for company, data in akjae_dict.items():
            merged["akjae"].append(f"{company}: {data['reason']} ({data['count']}íšŒ)")
        
        return merged
    
    def analyze_sentiment(self, categorized_news):
        """
        Generates a briefing summary and sentiment analysis (Good/Bad news).
        This replaces the original generate_briefing method from AIProcessor.
        """
        if not categorized_news:
            return None
            
        # í˜„ì¬ ëª¨ë“œ í™•ì¸
        current_mode = self.is_trading_day()
        is_first_day_after_holiday = self.is_first_trading_day_after_holiday()
        
        print(f"ğŸ“Š í˜„ì¬ ëª¨ë“œ: {'í‰ì¼ ì¥ ì¤‘' if current_mode == 'trading' else 'ì£¼ë§/ê³µíœ´ì¼ ëˆ„ì '}")
        if is_first_day_after_holiday:
            print(f"ğŸ“… íœ´ì¼ ë‹¤ìŒ ë‚  ëª¨ë“œ: í†µí•© ì‹œê·¸ë„ ì ìš©")
        
        # ë¸Œë¦¬í•‘ìš© ì „ì²´ ë‰´ìŠ¤ (24ì‹œê°„ ë²”ìœ„)
        briefing_context = ""
        for category, items in categorized_news.items():
            if items:
                briefing_context += f"\n[{category}]\n"
                for item in items[:30]: 
                    briefing_context += f"- {item['title']}\n"
        
        # ë§¤ë§¤ë´‡ìš© í•„í„°ë§ëœ ë‰´ìŠ¤ (ì¥ì™¸ ë‰´ìŠ¤ ê°€ì¤‘ì¹˜)
        trading_news = self.filter_trading_signals(categorized_news)
        trading_context = ""
        for category, items in trading_news.items():
            if items:
                trading_context += f"\n[{category}]\n"
                for item in items[:30]: 
                    weight = item.get('time_weight', 1.0)
                    trading_context += f"- [{weight}x] {item['title']}\n"
        
        # ë¸Œë¦¬í•‘ìš© í”„ë¡¬í”„íŠ¸
        briefing_prompt = f"""
        ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ê¸ˆìœµ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ë¶„ë¥˜ëœ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¬ë„ ìˆëŠ” ì•„ì¹¨ ë¸Œë¦¬í•‘ì„ ì‘ì„±í•˜ì„¸ìš”.

        í•„ìˆ˜ ê·œì¹™:
        1. ëª¨ë“  ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.
        2. ê° ì„¹ì…˜ì˜ ìš”ì•½ì€ "ì‚¬ì‹¤ - ì˜í–¥ - ì²´í¬í¬ì¸íŠ¸" êµ¬ì¡°ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìœ ê¸°ì ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”.

        ìˆ˜í–‰ ê³¼ì œ:
        1. **ì„¹ì…˜ë³„ ìš”ì•½**: ê° ì„¹ì…˜ì˜ í•µì‹¬ íë¦„ì„ ë‚ ì¹´ë¡­ê²Œ ìš”ì•½í•˜ì„¸ìš”.
            - í˜•ì‹ : "[ì‚¬ì‹¤] ~ë¼ëŠ” ì†Œì‹ì´ ìˆìœ¼ë‚˜, [ì˜í–¥] ì´ë¡œ ì¸í•´ ~ê°€ ì˜ˆìƒë˜ë¯€ë¡œ, [ì²´í¬í¬ì¸íŠ¸] í–¥í›„ ~ë¥¼ ì£¼ëª©í•´ì•¼ í•¨."
            - ì˜ˆì‹œ: "[ì‚¬ì‹¤] ë¯¸ ì—°ì¤€ì˜ ê¸ˆë¦¬ ë™ê²° ë°œí‘œê°€ ìˆì—ˆìœ¼ë‚˜, [ì˜í–¥] ì‹œì¥ì€ ì—¬ì „íˆ í•˜ë°˜ê¸° ì¸í•˜ ê¸°ëŒ€ê°ì„ ìœ ì§€í•˜ê³  ìˆì–´, [ì²´í¬í¬ì¸íŠ¸] ë‹¤ê°€ì˜¬ ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜(CPI) ë°œí‘œ ìˆ˜ì¹˜ë¥¼ ì˜ˆì˜ì£¼ì‹œí•´ì•¼ í•¨."
        2. **ê¸°ì—… ê°ì„± ë¶„ì„**: ì£¼ê°€ì— 'ì‹¤ì§ˆì 'ì¸ ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆëŠ” ê²°ì •ì ì¸ í˜¸ì¬(Hojae)ì™€ ì•…ì¬(Akjae)ë¥¼ ì°¾ìœ¼ì„¸ìš”.
           - í˜¸ì¬ ì„ ì •: ëŒ€ê·œëª¨ ìˆ˜ì£¼(ìˆ˜ë°±ì–µ ì› ì´ìƒ), M&A, í•µì‹¬ ê¸°ìˆ  í˜ì‹ , ì‹¤ì  í„´ì–´ë¼ìš´ë“œ (ë‹¨ìˆœ ì¸ì‚¬ë‚˜ ì†Œê·œëª¨ í˜‘ì•½ì€ ì œì™¸).
           - ì•…ì¬ ì„ ì •: ì–´ë‹ ì‡¼í¬, ë²•ì  ë¶„ìŸ, ëŒ€ê·œëª¨ ë¦¬ì½œ, ìê¸ˆ ìœ ë™ì„± ìœ„ê¸°, ì£¼ìš” ìƒì‚° ì‹œì„¤ ì‚¬ê³ .
           - ì´ìœ  í‘œê¸°: ê° ê¸°ì—… ì˜†ì— 10ì ì´ë‚´ì˜ ì•„ì£¼ ì§§ì€ ì‚¬ìœ ë¥¼ ë§ë¶™ì´ì„¸ìš”.
           - í˜•ì‹: "íšŒì‚¬ëª…: ì‚¬ìœ "
        
        Output JSON Format:
        {{
            "section_summaries": {{
                "ì •ì¹˜": "...",
                "ê²½ì œ/ê±°ì‹œ": "...",
                "ê¸°ì—…/ì‚°ì—…": "...",
                "ë¶€ë™ì‚°": "...",
                "êµ­ì œ": "..."
            }},
            "hojae": ["íšŒì‚¬ëª…: ì‚¬ìœ ", "íšŒì‚¬ëª…: ì‚¬ìœ "],
            "akjae": ["íšŒì‚¬ëª…: ì‚¬ìœ ", "íšŒì‚¬ëª…: ì‚¬ìœ "]
        }}
        
        News List:
        {briefing_context}
        """
        
        # ë§¤ë§¤ë´‡ìš© í”„ë¡¬í”„íŠ¸ (ê°€ì¤‘ì¹˜ ì ìš©)
        trading_prompt = f"""
        ë‹¹ì‹ ì€ ë§¤ë§¤ë´‡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë‰´ìŠ¤ ì¤‘ì—ì„œ ì˜¤ëŠ˜ì˜ ë§¤ë§¤ì— ì‹¤ì§ˆì ì¸ ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆëŠ” í˜¸ì¬/ì•…ì¬ë§Œ ì„ ë³„í•´ì£¼ì„¸ìš”.

        ì¤‘ìš” ê·œì¹™:
        1. [2.0x] í‘œì‹œëœ ì¥ì™¸ ë‰´ìŠ¤(ì–´ì œ 15:30~ì˜¤ëŠ˜ 08:30)ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤í•˜ì„¸ìš”.
        2. [1.0x] ì¥ì¤‘ ë‰´ìŠ¤ëŠ” ì´ë¯¸ ì£¼ê°€ì— ë°˜ì˜ë˜ì—ˆì„ ê°€ëŠ¥ì„±ì´ ë†’ìœ¼ë¯€ë¡œ ì‹ ì¤‘í•˜ê²Œ íŒë‹¨í•˜ì„¸ìš”.
        3. ì˜¤ëŠ˜ì˜ ë§¤ë§¤ ì „ëµì— í˜¼ì„ ì„ ì¤„ ìˆ˜ ìˆëŠ” ë‰´ìŠ¤ëŠ” ì œì™¸í•˜ì„¸ìš”.

        ì„ ë³„ ê¸°ì¤€:
        - í˜¸ì¬: ì¥ì™¸ ì‹œê°„ì— ë°œìƒí•œ ëŒ€ê·œëª¨ ìˆ˜ì£¼, M&A, ì‹¤ì  í„´ì–´ë¼ìš´ë“œ, í•µì‹¬ ê¸°ìˆ  ë‰´ìŠ¤
        - ì•…ì¬: ì¥ì™¸ ì‹œê°„ì— ë°œìƒí•œ ì–´ë‹ ì‡¼í¬, ë²•ì  ë¶„ìŸ, ë¦¬ì½œ, ìœ ë™ì„± ìœ„ê¸°

        Output JSON Format:
        {{
            "trading_hojae": ["íšŒì‚¬ëª…: ì‚¬ìœ ", "íšŒì‚¬ëª…: ì‚¬ìœ "],
            "trading_akjae": ["íšŒì‚¬ëª…: ì‚¬ìœ ", "íšŒì‚¬ëª…: ì‚¬ìœ "]
        }}
        
        Weighted News List:
        {trading_context}
        """
        
        try:
            # ë¸Œë¦¬í•‘ ë¶„ì„
            briefing_response = self.client.models.generate_content(
                model=config.model_flash,
                contents=briefing_prompt,
                config={'response_mime_type': 'application/json'}
            )
            briefing_data = json.loads(briefing_response.text)
            
            # ë§¤ë§¤ë´‡ìš© ë¶„ì„
            trading_response = self.client.models.generate_content(
                model=config.model_flash,
                contents=trading_prompt,
                config={'response_mime_type': 'application/json'}
            )
            trading_data = json.loads(trading_response.text)
            
            # ë‘ ë°ì´í„° ë³‘í•©
            final_data = {
                **briefing_data,
                "trading_hojae": trading_data.get("trading_hojae", []),
                "trading_akjae": trading_data.get("trading_akjae", []),
                "analysis_mode": current_mode,
                "is_holiday_next_day": is_first_day_after_holiday
            }
            
            # íœ´ì¼ ë‹¤ìŒ ë‚ ì´ë©´ ìºì‹œ ë³‘í•© ë° í†µí•© ë¦¬í¬íŠ¸
            if is_first_day_after_holiday:
                print("ğŸ”„ íœ´ì¼ ë‹¤ìŒ ë‚ : ìºì‹œ ë°ì´í„° í†µí•© ì¤‘...")
                final_data = self._merge_holiday_cache(final_data)
                self._clear_holiday_cache()
            
            # ëˆ„ì  ëª¨ë“œì¼ ê²½ìš° ìºì‹œ ì €ì¥
            elif current_mode == 'accumulation':
                today = datetime.now().strftime("%Y%m%d")
                cached_data = self.load_cached_data(today)
                
                if cached_data:
                    print(f"ğŸ”„ ìºì‹œëœ ë°ì´í„°ì™€ ë³‘í•© ì¤‘...")
                    merged_data = self.merge_sentiment_data(final_data, cached_data)
                    self.save_cached_data(merged_data, today)
                    return merged_data
                else:
                    self.save_cached_data(final_data, today)
                    return final_data
            else:
                # í‰ì¼ ì¥ ì¤‘ ëª¨ë“œëŠ” ê·¸ëŒ€ë¡œ ë°˜í™˜
                return final_data
                
        except Exception as e:
            print(f"Error generating sentiment analysis: {e}")
            return None
    
    def _merge_holiday_cache(self, current_data):
        """
        íœ´ì¼ ë‹¤ìŒ ë‚ ì— ìºì‹œëœ ëª¨ë“  ë°ì´í„°ë¥¼ ë³‘í•©
        """
        now = datetime.now()
        merged_data = {
            **current_data,
            "hojae": [],
            "akjae": [],
            "holiday_merged_dates": []
        }
        
        # ìµœê·¼ 3ì¼ê°„ì˜ ìºì‹œ ë°ì´í„° ìˆ˜ì§‘
        for i in range(1, 4):  # 1ì¼ì „, 2ì¼ì „, 3ì¼ì „
            past_date = now - timedelta(days=i)
            date_str = past_date.strftime("%Y%m%d")
            cached_data = self.load_cached_data(date_str)
            
            if cached_data:
                merged_data["holiday_merged_dates"].append(date_str)
                
                # í˜¸ì¬ ë°ì´í„° ë³‘í•©
                for item in cached_data.get("hojae", []):
                    if item not in merged_data["hojae"]:
                        merged_data["hojae"].append(item)
                
                # ì•…ì¬ ë°ì´í„° ë³‘í•©
                for item in cached_data.get("akjae", []):
                    if item not in merged_data["akjae"]:
                        merged_data["akjae"].append(item)
        
        # í˜„ì¬ ë°ì´í„° ì¶”ê°€
        merged_data["hojae"].extend(current_data.get("hojae", []))
        merged_data["akjae"].extend(current_data.get("akjae", []))
        
        # ì¤‘ë³µ ì œê±°
        merged_data["hojae"] = list(set(merged_data["hojae"]))
        merged_data["akjae"] = list(set(merged_data["akjae"]))
        
        print(f"âœ… íœ´ì¼ ë°ì´í„° í†µí•© ì™„ë£Œ: {len(merged_data['holiday_merged_dates'])}ì¼ê°„ ë°ì´í„° ë³‘í•©")
        
        return merged_data
    
    def _clear_holiday_cache(self):
        """
        íœ´ì¼ ìºì‹œ ì •ë¦¬
        """
        now = datetime.now()
        
        # ìµœê·¼ 3ì¼ê°„ ìºì‹œ íŒŒì¼ ì •ë¦¬
        for i in range(1, 4):
            past_date = now - timedelta(days=i)
            date_str = past_date.strftime("%Y%m%d")
            cache_file = self.get_cache_filename(date_str)
            
            if os.path.exists(cache_file):
                try:
                    os.remove(cache_file)
                    print(f"ğŸ—‘ï¸ ìºì‹œ íŒŒì¼ ì •ë¦¬: {cache_file}")
                except Exception as e:
                    print(f"ìºì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def generate_weekend_summary(self):
        """
        ì£¼ë§ì— ìŒ“ì¸ ë°ì´í„°ë¥¼ ì›”ìš”ì¼ ì•„ì¹¨ì— í•œ ë²ˆì— ì¶œë ¥
        Returns: ì£¼ë§ ì¢…í•© ìš”ì•½ ë°ì´í„°
        """
        print("ğŸ“… ì£¼ë§ ë°ì´í„° ì¢…í•© ë¶„ì„ ì‹œì‘...")
        
        # ì£¼ë§ ë‚ ì§œ ê³„ì‚° (ê¸ˆìš”ì¼ë¶€í„° ì¼ìš”ì¼ê¹Œì§€)
        now = datetime.now()
        
        # ì›”ìš”ì¼ì¸ì§€ í™•ì¸
        if now.weekday() != 0:  # 0ì€ ì›”ìš”ì¼
            print("âš ï¸ ì›”ìš”ì¼ì´ ì•„ë‹ˆì–´ì„œ ì£¼ë§ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ì£¼ë§ ë‚ ì§œë“¤ ê³„ì‚°
        friday = now - timedelta(days=3)
        saturday = now - timedelta(days=2) 
        sunday = now - timedelta(days=1)
        
        weekend_dates = [
            friday.strftime("%Y%m%d"),
            saturday.strftime("%Y%m%d"),
            sunday.strftime("%Y%m%d")
        ]
        
        print(f"ğŸ“Š ë¶„ì„ ëŒ€ìƒ ì£¼ë§: {friday.strftime('%m/%d')}~{sunday.strftime('%m/%d')}")
        
        # ì£¼ë§ ë°ì´í„° ìˆ˜ì§‘
        weekend_data = []
        for date_str in weekend_dates:
            cached_data = self.load_cached_data(date_str)
            if cached_data:
                cached_data["date"] = date_str
                weekend_data.append(cached_data)
        
        if not weekend_data:
            print("ğŸ“­ ì£¼ë§ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ì£¼ë§ ë°ì´í„° ì¢…í•© ë¶„ì„
        summary = self._analyze_weekend_data(weekend_data)
        
        return summary
    
    def _analyze_weekend_data(self, weekend_data):
        """
        ì£¼ë§ ë°ì´í„°ë¥¼ ì¢…í•© ë¶„ì„í•˜ì—¬ ìš”ì•½ ìƒì„±
        """
        print("ğŸ” ì£¼ë§ ë°ì´í„° ì¢…í•© ë¶„ì„ ì¤‘...")
        
        # ëª¨ë“  í˜¸ì¬/ì•…ì¬ ë°ì´í„° ìˆ˜ì§‘
        all_hojae = {}
        all_akjae = {}
        
        for day_data in weekend_data:
            date_str = day_data.get("date", "")
            
            # í˜¸ì¬ ë°ì´í„° ì²˜ë¦¬
            for item in day_data.get("hojae", []):
                if ":" in item:
                    company, reason = item.split(":", 1)
                    company = company.strip()
                    
                    if company not in all_hojae:
                        all_hojae[company] = {
                            "reasons": [],
                            "dates": [],
                            "count": 0
                        }
                    
                    all_hojae[company]["reasons"].append(reason.strip())
                    all_hojae[company]["dates"].append(date_str)
                    all_hojae[company]["count"] += 1
            
            # ì•…ì¬ ë°ì´í„° ì²˜ë¦¬
            for item in day_data.get("akjae", []):
                if ":" in item:
                    company, reason = item.split(":", 1)
                    company = company.strip()
                    
                    if company not in all_akjae:
                        all_akjae[company] = {
                            "reasons": [],
                            "dates": [],
                            "count": 0
                        }
                    
                    all_akjae[company]["reasons"].append(reason.strip())
                    all_akjae[company]["dates"].append(date_str)
                    all_akjae[company]["count"] += 1
        
        # ì£¼ë§ ìš”ì•½ ìƒì„±
        summary = {
            "weekend_dates": [data.get("date", "") for data in weekend_data],
            "hojae_summary": [],
            "akjae_summary": [],
            "top_hojae": [],
            "top_akjae": [],
            "total_hojae": len(all_hojae),
            "total_akjae": len(all_akjae)
        }
        
        # í˜¸ì¬ ìš”ì•½ (íšŒì‚¬ë³„ë¡œ ê·¸ë£¹í™”)
        for company, data in sorted(all_hojae.items(), key=lambda x: x[1]["count"], reverse=True):
            summary["hojae_summary"].append({
                "company": company,
                "count": data["count"],
                "reasons": data["reasons"],
                "dates": data["dates"]
            })
        
        # ì•…ì¬ ìš”ì•½
        for company, data in sorted(all_akjae.items(), key=lambda x: x[1]["count"], reverse=True):
            summary["akjae_summary"].append({
                "company": company,
                "count": data["count"],
                "reasons": data["reasons"],
                "dates": data["dates"]
            })
        
        # ìƒìœ„ í˜¸ì¬/ì•…ì¬ (3íšŒ ì´ìƒ ì–¸ê¸‰ëœ ê¸°ì—…)
        summary["top_hojae"] = [item for item in summary["hojae_summary"] if item["count"] >= 3]
        summary["top_akjae"] = [item for item in summary["akjae_summary"] if item["count"] >= 3]
        
        print(f"âœ… ì£¼ë§ ìš”ì•½ ì™„ë£Œ: í˜¸ì¬ {len(all_hojae)}ê°œ, ì•…ì¬ {len(all_akjae)}ê°œ")
        
        return summary
    
    def format_weekend_summary_message(self, weekend_summary):
        """
        ì£¼ë§ ìš”ì•½ì„ í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ë¡œ í¬ë§·íŒ…
        """
        if not weekend_summary:
            return None
        
        dates = weekend_summary.get("weekend_dates", [])
        if dates:
            date_range = f"{dates[-1][-4:]}-{dates[-1][4:6]}-{dates[-1][6:8]} ~ {dates[0][-4:]}-{dates[0][4:6]}-{dates[0][6:8]}"
        else:
            date_range = "ì£¼ë§"
        
        lines = [
            f"ğŸ“Š ì£¼ë§ ì¢…í•© ë‰´ìŠ¤ ìš”ì•½ ({date_range})",
            "",
            f"ğŸ“ˆ í˜¸ì¬ ê¸°ì—…: {weekend_summary.get('total_hojae', 0)}ê°œ",
            f"ğŸ“‰ ì•…ì¬ ê¸°ì—…: {weekend_summary.get('total_akjae', 0)}ê°œ",
            ""
        ]
        
        # ìƒìœ„ í˜¸ì¬ ê¸°ì—…
        top_hojae = weekend_summary.get("top_hojae", [])
        if top_hojae:
            lines.append("ğŸ”¥ ì£¼ìš” í˜¸ì¬ ê¸°ì—…:")
            for item in top_hojae[:5]:  # ìƒìœ„ 5ê°œ
                lines.append(f"  â€¢ {item['company']}: {item['count']}íšŒ")
            lines.append("")
        
        # ìƒìœ„ ì•…ì¬ ê¸°ì—…
        top_akjae = weekend_summary.get("top_akjae", [])
        if top_akjae:
            lines.append("âš ï¸ ì£¼ìš” ì•…ì¬ ê¸°ì—…:")
            for item in top_akjae[:5]:  # ìƒìœ„ 5ê°œ
                lines.append(f"  â€¢ {item['company']}: {item['count']}íšŒ")
            lines.append("")
        
        lines.append("ğŸ“± ìì„¸í•œ ë‚´ìš©ì€ ì›¹ì‚¬ì´íŠ¸ì—ì„œ í™•ì¸í•˜ì„¸ìš”!")
        
        return "\n".join(lines)

    def analyze_sentiment(self, categorized_news):
        """
        Generates a briefing summary and sentiment analysis (Good/Bad news).
        This replaces the original generate_briefing method from AIProcessor.
        """
        if not categorized_news:
            return None
            
        # Context preparation: Flatten the list but keep categories
        context = ""
        for category, items in categorized_news.items():
            if items:
                context += f"\n[{category}]\n"
                # Increase context to top 30 to catch more diverse news (like Akjae)
                for item in items[:30]: 
                    context += f"- {item['title']}\n"
        
        prompt = f"""
        ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ê¸ˆìœµ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ë¶„ë¥˜ëœ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¬ë„ ìˆëŠ” ì•„ì¹¨ ë¸Œë¦¬í•‘ì„ ì‘ì„±í•˜ì„¸ìš”.

        í•„ìˆ˜ ê·œì¹™:
        1. ëª¨ë“  ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.
        2. ê° ì„¹ì…˜ì˜ ìš”ì•½ì€ "ì‚¬ì‹¤ - ì˜í–¥ - ì²´í¬í¬ì¸íŠ¸" êµ¬ì¡°ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìœ ê¸°ì ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”.

        ìˆ˜í–‰ ê³¼ì œ:
        1. **ì„¹ì…˜ë³„ ìš”ì•½**: ê° ì„¹ì…˜ì˜ í•µì‹¬ íë¦„ì„ ë‚ ì¹´ë¡­ê²Œ ìš”ì•½í•˜ì„¸ìš”.
            - í˜•ì‹ : "[ì‚¬ì‹¤] ~ë¼ëŠ” ì†Œì‹ì´ ìˆìœ¼ë‚˜, [ì˜í–¥] ì´ë¡œ ì¸í•´ ~ê°€ ì˜ˆìƒë˜ë¯€ë¡œ, [ì²´í¬í¬ì¸íŠ¸] í–¥í›„ ~ë¥¼ ì£¼ëª©í•´ì•¼ í•¨."
            - ì˜ˆì‹œ: "[ì‚¬ì‹¤] ë¯¸ ì—°ì¤€ì˜ ê¸ˆë¦¬ ë™ê²° ë°œí‘œê°€ ìˆì—ˆìœ¼ë‚˜, [ì˜í–¥] ì‹œì¥ì€ ì—¬ì „íˆ í•˜ë°˜ê¸° ì¸í•˜ ê¸°ëŒ€ê°ì„ ìœ ì§€í•˜ê³  ìˆì–´, [ì²´í¬í¬ì¸íŠ¸] ë‹¤ê°€ì˜¬ ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜(CPI) ë°œí‘œ ìˆ˜ì¹˜ë¥¼ ì˜ˆì˜ì£¼ì‹œí•´ì•¼ í•¨."
        2. **ê¸°ì—… ê°ì„± ë¶„ì„**: ì£¼ê°€ì— 'ì‹¤ì§ˆì 'ì¸ ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆëŠ” ê²°ì •ì ì¸ í˜¸ì¬(Hojae)ì™€ ì•…ì¬(Akjae)ë¥¼ ì°¾ìœ¼ì„¸ìš”.
           - í˜¸ì¬ ì„ ì •: ëŒ€ê·œëª¨ ìˆ˜ì£¼(ìˆ˜ë°±ì–µ ì› ì´ìƒ), M&A, í•µì‹¬ ê¸°ìˆ  í˜ì‹ , ì‹¤ì  í„´ì–´ë¼ìš´ë“œ (ë‹¨ìˆœ ì¸ì‚¬ë‚˜ ì†Œê·œëª¨ í˜‘ì•½ì€ ì œì™¸).
           - ì•…ì¬ ì„ ì •: ì–´ë‹ ì‡¼í¬, ë²•ì  ë¶„ìŸ, ëŒ€ê·œëª¨ ë¦¬ì½œ, ìê¸ˆ ìœ ë™ì„± ìœ„ê¸°, ì£¼ìš” ìƒì‚° ì‹œì„¤ ì‚¬ê³ .
           - ì´ìœ  í‘œê¸°: ê° ê¸°ì—… ì˜†ì— 10ì ì´ë‚´ì˜ ì•„ì£¼ ì§§ì€ ì‚¬ìœ ë¥¼ ë§ë¶™ì´ì„¸ìš”.
           - í˜•ì‹: "íšŒì‚¬ëª…: ì‚¬ìœ "
        
        Output JSON Format:
        {{
            "section_summaries": {{
                "ì •ì¹˜": "...",
                "ê²½ì œ/ê±°ì‹œ": "...",
                "ê¸°ì—…/ì‚°ì—…": "...",
                "ë¶€ë™ì‚°": "...",
                "êµ­ì œ": "..."
            }},
            "hojae": ["íšŒì‚¬ëª…: ì‚¬ìœ ", "íšŒì‚¬ëª…: ì‚¬ìœ "],
            "akjae": ["íšŒì‚¬ëª…: ì‚¬ìœ ", "íšŒì‚¬ëª…: ì‚¬ìœ "]
        }}
        
        News List:
        {context}
        """
        
        try:
            response = self.client.models.generate_content(
                model=config.model_flash,
                contents=prompt,
                config={'response_mime_type': 'application/json'}
            )
            return json.loads(response.text)
        except Exception as e:
            print(f"Error generating sentiment analysis: {e}")
            return None

    def extract_hojae_list(self, briefing_data):
        """
        Extract hojae list from briefing data.
        Returns a list of hojae items.
        """
        if not briefing_data:
            return []
        
        return briefing_data.get("hojae", [])

    def extract_akjae_list(self, briefing_data):
        """
        Extract akjae list from briefing data.
        Returns a list of akjae items.
        """
        if not briefing_data:
            return []
        
        return briefing_data.get("akjae", [])

    def get_hojae_count(self, briefing_data):
        """
        Get the count of hojae items.
        """
        return len(self.extract_hojae_list(briefing_data))

    def get_akjae_count(self, briefing_data):
        """
        Get the count of akjae items.
        """
        return len(self.extract_akjae_list(briefing_data))

    def format_telegram_message(self, briefing_data, date_str=None, total_news_count=None):
        """
        Format telegram message for hojae notification.
        Returns a formatted message string.
        """
        hojae_list = self.extract_hojae_list(briefing_data)
        hojae_count = len(hojae_list)
        
        if not hojae_list:
            return None
        
        # Compose summary header (date, total news, hojae count)
        headline = "ğŸ“° ëª¨ë‹ë‰´ìŠ¤ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤"
        if date_str:
            headline += f" ({date_str})"

        summary_parts = []
        if total_news_count is not None:
            summary_parts.append(f"ì´ {total_news_count}ê±´ì˜ ë‰´ìŠ¤")
        summary_parts.append(f"í˜¸ì¬ ê¸°ì—…: {hojae_count}ê³³")
        summary_line = " / ".join(summary_parts)

        list_title = f"ğŸ“ˆ í˜¸ì¬ ê¸°ì—… ë¦¬ìŠ¤íŠ¸ ({date_str})" if date_str else "ğŸ“ˆ í˜¸ì¬ ê¸°ì—… ë¦¬ìŠ¤íŠ¸"

        lines = [headline, summary_line, "", list_title]
        for item in hojae_list:
            lines.append(f"- {item}")
        message = "\n".join(lines)
        
        return message

    def get_section_summaries(self, briefing_data):
        """
        Extract section summaries from briefing data.
        """
        if not briefing_data:
            return {}
        
        return briefing_data.get("section_summaries", {})

    def has_sentiment_data(self, briefing_data):
        """
        Check if briefing data contains sentiment analysis (hojae/akjae).
        """
        if not briefing_data:
            return False
        
        return bool(briefing_data.get("hojae") or briefing_data.get("akjae"))

if __name__ == "__main__":
    # Test the SentimentAnalyzer
    analyzer = SentimentAnalyzer()
    
    print("ğŸ§ª SentimentAnalyzer í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # í…ŒìŠ¤íŠ¸ 1: ë‚ ì§œ íŒë‹¨ ë¡œì§
    print(f"ğŸ“… í˜„ì¬ ëª¨ë“œ: {analyzer.is_trading_day()}")
    
    # í…ŒìŠ¤íŠ¸ 2: ìºì‹œ ê¸°ëŠ¥
    test_data = {
        "hojae": ["ì‚¼ì„±ì „ì: ë°˜ë„ì²´ í˜¸ì¬", "LGí™”í•™: ë°°í„°ë¦¬ í˜¸ì¬"],
        "akjae": ["í˜„ëŒ€ì°¨: ë¦¬ì½œ ì•…ì¬"],
        "section_summaries": {"ì •ì¹˜": "í…ŒìŠ¤íŠ¸ ìš”ì•½"}
    }
    
    analyzer.save_cached_data(test_data, "20260117")
    loaded_data = analyzer.load_cached_data("20260117")
    print(f"âœ… ìºì‹œ í…ŒìŠ¤íŠ¸: {'ì„±ê³µ' if loaded_data else 'ì‹¤íŒ¨'}")
    
    # í…ŒìŠ¤íŠ¸ 3: ë°ì´í„° ë³‘í•©
    current_data = {
        "hojae": ["ì‚¼ì„±ì „ì: ì‹ ì œí’ˆ ì¶œì‹œ", "SKí•˜ì´ë‹‰ìŠ¤: ìˆ˜ì£¼"],
        "akjae": ["í˜„ëŒ€ì°¨: ë¦¬ì½œ ì•…ì¬", "ê¸°ì•„: ë¶€í’ˆ ê²°í•¨"]
    }
    
    merged = analyzer.merge_sentiment_data(current_data, test_data)
    print(f"âœ… ë³‘í•© í…ŒìŠ¤íŠ¸: í˜¸ì¬ {len(merged['hojae'])}ê°œ, ì•…ì¬ {len(merged['akjae'])}ê°œ")
    
    # í…ŒìŠ¤íŠ¸ 4: ì£¼ë§ ìš”ì•½ (ì›”ìš”ì¼ì´ ì•„ë‹ˆë©´ None ë°˜í™˜)
    weekend_summary = analyzer.generate_weekend_summary()
    print(f"ğŸ“… ì£¼ë§ ìš”ì•½ í…ŒìŠ¤íŠ¸: {'ì„±ê³µ' if weekend_summary else 'ì›”ìš”ì¼ì´ ì•„ë‹˜'}")
    
    print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
